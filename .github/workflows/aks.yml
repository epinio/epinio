name: AKS-CI

on:
  pull_request:
    paths:
      - 'acceptance/install/scenario3_test.go'
      - '.github/workflows/aks.yml'
  schedule:
    - cron:  '0 5 * * *'
  workflow_dispatch:
    inputs:
      azure_credentials:
        description: "AZURE_CREDENTIALS"
        required: false
        default: ""
      aks_domain:
        description: "AKS_DOMAIN to use, managed via Route53's AWS_ZONE_ID"
        required: false
        default: ""
      aws_zone_id:
        description: "AWS_ZONE_ID"
        required: false
        default: ""
      keep_cluster:
        description: "Keep the cluster afterwards? (empty/yes)"
        required: false
        default: ""

env:
  SETUP_GO_VERSION: '^1.13.7'
  GINKGO_NODES: 1
  FLAKE_ATTEMPTS: 1

jobs:
  acceptance-scenario3:
    runs-on: windows-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Get All Git Tags
        run: git fetch --force --prune --unshallow --tags

      - name: Setup Go
        uses: actions/setup-go@v2
        with:
          go-version: ${{ env.SETUP_GO_VERSION }}
      - name: Setup Ginkgo Test Framework
        run: go install github.com/onsi/ginkgo/ginkgo@v1.16.2

      # The system domain is managed by route53, we need credentials to update
      # it to the loadbalancer's IP
      - name: Configure AWS credentials for Route53
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-2

      # follow https://github.com/marketplace/actions/azure-login#configure-deployment-credentials
      # az group create --name epinioCI --location westeurope
      # az ad sp create-for-rbac --name "epinioCI" --sdk-auth --role contributor \
      #   --scopes /subscriptions/{id}/resourceGroups/epinioC
      - uses: azure/login@v1
        with:
          creds: ${{ github.events.inputs.azure_credentials || secrets.AZURE_CREDENTIALS }}

      - name: Create AKS cluster
        id: create-cluster
        shell: bash
        run: |
          id=$RANDOM
          echo '::set-output name=ID::'$id
          az aks create --resource-group epinioCI --name epinioCI$id --node-count 2 --generate-ssh-keys
          az aks get-credentials --resource-group epinioCI --name epinioCI$id --file kubeconfig
          # list existing clusters
          az aks list | jq '.[] | .name + " " + (.powerState|tostring)'

      - name: Installation Acceptance Tests
        env:
          REGEX: Scenario3
          REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
          REGISTRY_PASSWORD: ${{ secrets.DOCKERHUB_TOKEN }}
          AWS_ZONE_ID: ${{ github.events.inputs.aws_zone_id || secrets.AWS_ZONE_ID }}
          AKS_DOMAIN: ${{ github.events.inputs.aks_domain || secrets.AKS_DOMAIN }}
          EPINIO_TIMEOUT_MULTIPLIER: 3
        shell: bash
        run: |
          export KUBECONFIG=$PWD/kubeconfig
          make test-acceptance-install

      - name: Delete AKS cluster
        # We always tear down the cluster, to avoid costs. Except when running
        # manually and keep_cluster was set to a non-empty string, like "yes"
        # TODO this was not called, when scheduled and tests failed
        if: ${{ always() && !github.event.inputs.keep_cluster }}
        shell: bash
        run: |
          echo "debug keep_cluster: ${{ github.event.inputs.keep_cluster }}"
          id="${{ steps.create-cluster.outputs.ID }}"
          az aks delete --resource-group epinioCI --name epinioCI$id --yes
